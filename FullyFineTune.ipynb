{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPB5nE5UUCNYAhP1jeB1dWF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashev2021/Fine-Tuning-LLM/blob/main/FullyFineTune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AIt6RSmPKH8U"
      },
      "outputs": [],
      "source": [
        "!pip install \"datasets>=2.18.0,<3\"\n",
        "# deploy in Gradio\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers>=4.38.2 sentence-transformers>=2.5.1 setfit>=1.0.3 accelerate>=0.27.2 seqeval>=1.2.2"
      ],
      "metadata": {
        "id": "ova20jIaLnGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Prepare data and splits\n",
        "imdb_data = load_dataset(\"mteb/imdb\")\n",
        "\n",
        "train_data, test_data = imdb_data[\"train\"], imdb_data[\"test\"]\n",
        "\n",
        "\n",
        "train_data = train_data.shuffle(seed=42).select(range(2000))\n",
        "test_data = test_data.shuffle(seed=42).select(range(1000))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LVK4QeVILwK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Supervised classification Fine tune everything(Huggingface train)\n",
        "\n",
        "# model and tokenize\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "\n",
        "#pretrained model + tokenizer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xKAVluRAMc1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Collator\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# pad to longest sentence\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# preprocess\n",
        "def preprocess_function(examples):\n",
        "   \"\"\"Tokenize input data\"\"\"\n",
        "   return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "# tokenize train\n",
        "tokenized_train = train_data.map(preprocess_function, batched=True)\n",
        "tokenized_test = test_data.map(preprocess_function, batched=True)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HIfGEyZ2OGv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model with F1\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Calculate F1 score\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    load_f1 = evaluate.load(\"f1\")\n",
        "    f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "    return {\"f1\": f1}\n"
      ],
      "metadata": {
        "id": "cGjOq-ypOvZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training arguments for parameter tuning\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "   \"model\",\n",
        "   learning_rate=2e-5,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   num_train_epochs=1,\n",
        "   weight_decay=0.01,\n",
        "   save_strategy=\"epoch\",\n",
        "   report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Trainer which executes the training process\n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IppKyw3UTiVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "trainer.train()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BIZKTnjpT7Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eval results\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FtnMCz-wUJZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x1O8-zA_9tFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#save fine-tuned model\n",
        "trainer.save_model(\"my_finetuned_model\")\n"
      ],
      "metadata": {
        "id": "Cw68I9zt1sqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deploy with Gradio to compare\n",
        "\n",
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load your fine-tuned model\n",
        "fine_tuned_model_path = \"my_finetuned_model\"\n",
        "fine_tuned_classifier = pipeline(\"text-classification\", model=fine_tuned_model_path, tokenizer=fine_tuned_model_path)\n",
        "\n",
        "# Load pretrained sentiment model from Hugging Face Hub\n",
        "pretrained_classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased\")\n",
        "\n",
        "# Label mapping\n",
        "label_map = {\n",
        "    \"LABEL_0\": \"negative\",\n",
        "    \"LABEL_1\": \"positive\",\n",
        "    \"NEGATIVE\": \"negative\",\n",
        "    \"POSITIVE\": \"positive\",\n",
        "}\n",
        "\n",
        "def compare_models(text):\n",
        "    # Fine-tuned model\n",
        "    ft_pred = fine_tuned_classifier(text)[0]\n",
        "    ft_label = label_map.get(ft_pred[\"label\"], ft_pred[\"label\"])\n",
        "    ft_score = round(ft_pred[\"score\"], 4)\n",
        "    ft_result = f\"Label: {ft_label}, Confidence: {ft_score}\"\n",
        "\n",
        "    # Pretrained model\n",
        "    pre_pred = pretrained_classifier(text)[0]\n",
        "    pre_label = label_map.get(pre_pred[\"label\"], pre_pred[\"label\"])\n",
        "    pre_score = round(pre_pred[\"score\"], 4)\n",
        "    pre_result = f\"Label: {pre_label}, Confidence: {pre_score}\"\n",
        "\n",
        "    return ft_result, pre_result\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ðŸŽ¬ Compare Fine-Tuned vs Pretrained Sentiment Models\")\n",
        "    gr.Markdown(\"Enter a movie review below to compare predictions.\")\n",
        "\n",
        "    input_text = gr.Textbox(label=\"Movie Review\", lines=4, placeholder=\"Type your review here...\")\n",
        "    classify_btn = gr.Button(\"Classify\")\n",
        "\n",
        "    with gr.Row():\n",
        "        ft_output = gr.Textbox(label=\"Fine-Tuned Model Prediction\", interactive=False)\n",
        "        pre_output = gr.Textbox(label=\"Pretrained Model Prediction\", interactive=False)\n",
        "\n",
        "    classify_btn.click(compare_models, inputs=input_text, outputs=[ft_output, pre_output])\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "KBCgevBd6V32"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}